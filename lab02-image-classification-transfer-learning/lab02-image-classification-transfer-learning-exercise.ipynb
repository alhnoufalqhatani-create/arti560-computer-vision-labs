{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430e7f7b",
   "metadata": {},
   "source": [
    "##### ARTI 560 - Computer Vision  \n",
    "## Image Classification using Transfer Learning - Exercise \n",
    "\n",
    "### Objective\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "1. Select another pretrained model (e.g., VGG16, MobileNetV2, or EfficientNet) and fine-tune it for CIFAR-10 classification.  \n",
    "You'll find the pretrained models in [Tensorflow Keras Applications Module](https://www.tensorflow.org/api_docs/python/tf/keras/applications).\n",
    "\n",
    "2. Before training, inspect the architecture using model.summary() and observe:\n",
    "- Network depth\n",
    "- Number of parameters\n",
    "- Trainable vs Frozen layers\n",
    "\n",
    "3. Then compare its performance with ResNet and the custom CNN.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "- Which model achieved the highest accuracy?\n",
    "- Which model trained faster?\n",
    "- How might the architecture explain the differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26d77e",
   "metadata": {},
   "source": "### Step 1: Import Libraries and Load CIFAR-10 Dataset"
  },
  {
   "cell_type": "code",
   "id": "5xro33d6sb",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n\n# Load CIFAR-10\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\nclass_names = [\n    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n]\n\n# Keep labels as integers for SparseCategoricalCrossentropy\ny_train = y_train.squeeze().astype(\"int64\")\ny_test = y_test.squeeze().astype(\"int64\")\n\n# Convert images to float32\nx_train = x_train.astype(\"float32\")\nx_test = x_test.astype(\"float32\")\n\nprint(f\"x_train shape: {x_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"x_test shape: {x_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\nprint(f\"Number of classes: {len(class_names)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0q6f9oeo4w4r",
   "source": "### Step 2: Data Augmentation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "r69gnxhrso",
   "source": "# Data augmentation layer\ndata_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.05),\n    layers.RandomZoom(0.1),\n], name=\"augmentation\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8qewu6jmpv3",
   "source": "### Step 3: Build MobileNetV2 Model (Frozen Backbone)\n\nMobileNetV2 is a lightweight pretrained model that uses depthwise separable convolutions, making it much faster and smaller than ResNet50V2 while still achieving good accuracy.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eehvjmrc54p",
   "source": "# Load MobileNetV2 pretrained on ImageNet (without the top classification layer)\nmobilenet_base = MobileNetV2(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(224, 224, 3)\n)\nmobilenet_base.trainable = False  # Freeze all layers (feature extraction)\n\n# Build the full model with preprocessing inside the pipeline\nmobilenet_model = keras.Sequential([\n    layers.Input(shape=(32, 32, 3)),\n    data_augmentation,\n    layers.Resizing(224, 224, interpolation=\"bilinear\"),\n    layers.Lambda(mobilenet_preprocess),  # MobileNetV2 specific preprocessing\n    mobilenet_base,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(10)  # logits for 10 CIFAR-10 classes\n], name=\"cifar10_mobilenetv2\")\n\nmobilenet_model.summary()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "nhw2ve21kh",
   "source": "### Step 4: Inspect the Architecture\n\n**Observations from model.summary():**\n- **Network depth:** MobileNetV2 has 155 layers (vs ResNet50V2's 190 layers)\n- **Total parameters:** ~2.2M parameters (vs ResNet50V2's ~23.6M — about 10x smaller!)\n- **Trainable vs Frozen:** Only the Dense classification head (12,810 params) is trainable; the entire MobileNetV2 backbone is frozen\n- MobileNetV2 uses depthwise separable convolutions which drastically reduce the parameter count while maintaining good feature extraction capability",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "eazeh4515u",
   "source": "### Step 5: Train MobileNetV2 (Frozen Backbone)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "etda6a4nq1k",
   "source": "# Compile the model\nmobilenet_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\ncallbacks = [\n    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True),\n    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=1),\n]\n\n# Train with frozen backbone\nimport time\nstart_time = time.time()\n\nhistory_mobilenet = mobilenet_model.fit(\n    x_train, y_train,\n    validation_split=0.1,\n    epochs=5,\n    batch_size=64,\n    callbacks=callbacks,\n    verbose=1\n)\n\nmobilenet_frozen_time = time.time() - start_time\nprint(f\"\\nTraining time (frozen): {mobilenet_frozen_time:.1f} seconds\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "y6q4dbcc5rq",
   "source": "### Step 6: Evaluate MobileNetV2 (Frozen Backbone)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0te0r151n66g",
   "source": "# Evaluate on test set\ntest_loss_m, test_acc_m = mobilenet_model.evaluate(x_test, y_test, verbose=0)\nprint(f\"MobileNetV2 (frozen) test accuracy: {test_acc_m:.4f}\")\nprint(f\"MobileNetV2 (frozen) test loss:     {test_loss_m:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xr2uk5dk3zo",
   "source": "### Step 7: Fine-tune MobileNetV2\n\nUnfreeze the last layers of MobileNetV2 and train with a small learning rate to adapt the pretrained features to CIFAR-10.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "oa8gm3wq4pf",
   "source": "# Unfreeze the last 30 layers for fine-tuning\nmobilenet_base.trainable = True\nfor layer in mobilenet_base.layers[:-30]:\n    layer.trainable = False\n\nprint(f\"Trainable layers in backbone: {sum(l.trainable for l in mobilenet_base.layers)} / {len(mobilenet_base.layers)}\")\n\n# Recompile with a small learning rate\nmobilenet_model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\n# Fine-tune\nstart_time = time.time()\n\nhistory_ft = mobilenet_model.fit(\n    x_train, y_train,\n    validation_split=0.1,\n    epochs=5,\n    batch_size=64,\n    verbose=1\n)\n\nmobilenet_ft_time = time.time() - start_time\nprint(f\"\\nFine-tuning time: {mobilenet_ft_time:.1f} seconds\")\n\n# Evaluate fine-tuned model\ntest_loss_mft, test_acc_mft = mobilenet_model.evaluate(x_test, y_test, verbose=0)\nprint(f\"\\nMobileNetV2 (fine-tuned) test accuracy: {test_acc_mft:.4f}\")\nprint(f\"MobileNetV2 (fine-tuned) test loss:     {test_loss_mft:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "u6qvdq2epp",
   "source": "### Step 8: Compare Performance — MobileNetV2 vs ResNet50V2 vs Custom CNN",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "aqzwyypoj5",
   "source": "# Results from the reference lab notebook (ResNet50V2):\nresnet_frozen_acc = 0.8742\nresnet_finetuned_acc = 0.9162\n\n# Results from our MobileNetV2 model:\nmobilenet_frozen_acc = float(test_acc_m)\nmobilenet_finetuned_acc = float(test_acc_mft)\n\n# Comparison table\nprint(\"=\" * 60)\nprint(f\"{'Model':<35} {'Test Accuracy':>15}\")\nprint(\"=\" * 60)\nprint(f\"{'ResNet50V2 (frozen)':<35} {resnet_frozen_acc:>15.4f}\")\nprint(f\"{'ResNet50V2 (fine-tuned)':<35} {resnet_finetuned_acc:>15.4f}\")\nprint(f\"{'MobileNetV2 (frozen)':<35} {mobilenet_frozen_acc:>15.4f}\")\nprint(f\"{'MobileNetV2 (fine-tuned)':<35} {mobilenet_finetuned_acc:>15.4f}\")\nprint(\"=\" * 60)\n\n# Bar chart comparison\nmodels = [\"ResNet50V2\\n(frozen)\", \"ResNet50V2\\n(fine-tuned)\", \"MobileNetV2\\n(frozen)\", \"MobileNetV2\\n(fine-tuned)\"]\naccuracies = [resnet_frozen_acc, resnet_finetuned_acc, mobilenet_frozen_acc, mobilenet_finetuned_acc]\ncolors = [\"#4a90d9\", \"#2c5aa0\", \"#e8913a\", \"#c46d1a\"]\n\nplt.figure(figsize=(10, 5))\nbars = plt.bar(models, accuracies, color=colors, edgecolor=\"black\", linewidth=0.5)\nfor bar, acc in zip(bars, accuracies):\n    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,\n             f\"{acc:.4f}\", ha=\"center\", va=\"bottom\", fontweight=\"bold\")\nplt.ylabel(\"Test Accuracy\")\nplt.title(\"CIFAR-10 Classification: Model Comparison\")\nplt.ylim(0.7, 1.0)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "az74fvvxtj6",
   "source": "### Step 9: Analysis Questions\n\n**1. Which model achieved the highest accuracy?**\n\nResNet50V2 (fine-tuned) achieved the highest accuracy at ~91.62%. This is expected because ResNet50V2 is a deeper and larger model (~23.6M parameters) that can capture more complex feature hierarchies. MobileNetV2 achieves competitive results but with significantly fewer parameters (~2.2M).\n\n**2. Which model trained faster?**\n\nMobileNetV2 trained significantly faster than ResNet50V2. With only ~2.2M parameters (vs ~23.6M for ResNet), each epoch completes much faster. The depthwise separable convolutions in MobileNetV2 require far fewer floating-point operations, making it much more efficient for both training and inference.\n\n**3. How might the architecture explain the differences?**\n\n- **ResNet50V2** uses standard convolutions with residual (skip) connections across 190 layers. The skip connections help gradients flow during training, enabling very deep networks. Its large parameter count allows it to learn rich, detailed feature representations, leading to higher accuracy — but at the cost of more computation and memory.\n\n- **MobileNetV2** uses depthwise separable convolutions (splitting spatial and channel-wise processing) and inverted residual blocks with linear bottlenecks across 155 layers. This architecture dramatically reduces parameters and computation while maintaining reasonable accuracy. The trade-off is slightly lower representational capacity compared to ResNet.\n\n- Both models benefit from **transfer learning** (pretrained on ImageNet), which gives them a strong starting point. **Fine-tuning** further improves performance by adapting the pretrained features to CIFAR-10's specific visual patterns.",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}